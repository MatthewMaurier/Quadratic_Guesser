{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3yFEJiDVspR",
        "outputId": "1280cd59-cb67-4dcc-8ccf-79c053c58d6a"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x8NWRzcLWRtX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9ee6Dyp8V_v-"
      },
      "outputs": [],
      "source": [
        "xy_data_Path = \"C:\\\\Users\\\\Matth\\\\OneDrive\\\\Desktop\\\\Summer\\\\Python\\\\Quadratic_Guesser\\\\.gitignore\\\\xy_data.csv\"\n",
        "xy_data = pd.read_csv(xy_data_Path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6PYB4iXSWA3m"
      },
      "outputs": [],
      "source": [
        "abc_data_Path = \"C:\\\\Users\\\\Matth\\\\OneDrive\\\\Desktop\\\\Summer\\\\Python\\\\Quadratic_Guesser\\\\.gitignore\\\\abc_data.csv\"\n",
        "abc_data = pd.read_csv(abc_data_Path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SPSkM6CoWIep"
      },
      "outputs": [],
      "source": [
        "all_data=pd.DataFrame.join(xy_data,abc_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zbZDdsNrWLGL"
      },
      "outputs": [],
      "source": [
        "training_data, validation_data = train_test_split(all_data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IU6Z2UZJWZCT"
      },
      "outputs": [],
      "source": [
        "X_traine = training_data.iloc[0:8000,0:500]\n",
        "y_traine = training_data.iloc[0:8000,500:503]\n",
        "\n",
        "X_vale = validation_data.iloc[0:2000:,0:500]\n",
        "y_vale = validation_data.iloc[0:2000,500:503]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xdsarvUOWiSu"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_traine)\n",
        "X_train = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_traine.to_numpy(), dtype=torch.float32)\n",
        "\n",
        "X_val_scaled = scaler.transform(X_vale)\n",
        "X_val = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_vale.to_numpy(), dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NOUNBrs2XBax"
      },
      "outputs": [],
      "source": [
        "dataset = TensorDataset(X_train, y_train)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "valset = TensorDataset(X_val, y_val)\n",
        "val_loader = DataLoader(valset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7OPrlkQgXL0x"
      },
      "outputs": [],
      "source": [
        "class FeedforwardNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(FeedforwardNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xDDg5AUqXQtN"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "input_size = 500  # Number of y-coordinates\n",
        "hidden_size = 128\n",
        "output_size = 3   # Number of coefficients\n",
        "model = FeedforwardNN(input_size, hidden_size, output_size).to(device)\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005, weight_decay = 1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FeedforwardNN(\n",
              "  (fc1): Linear(in_features=500, out_features=128, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize weights\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "model.apply(weights_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    return val_loss / len(val_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs1OvHEBXRdW",
        "outputId": "b68b5371-74db-46f9-fc4f-35f4612de322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 194.8517; Val loss = 1966.5705599060059\n",
            "Epoch [2/100], Loss: 238.3549; Val loss = 1927.1042683105468\n",
            "Epoch [3/100], Loss: 108.0880; Val loss = 1885.4487338867189\n",
            "Epoch [4/100], Loss: 188.7159; Val loss = 1833.0190469360352\n",
            "Epoch [5/100], Loss: 92.4311; Val loss = 1781.734815673828\n",
            "Epoch [6/100], Loss: 65.5716; Val loss = 1716.6899785766602\n",
            "Epoch [7/100], Loss: 14748.5225; Val loss = 1647.6000290527343\n",
            "Epoch [8/100], Loss: 85.6491; Val loss = 1573.9204282226563\n",
            "Epoch [9/100], Loss: 71.1064; Val loss = 1489.3744179077148\n",
            "Epoch [10/100], Loss: 65.2948; Val loss = 1429.4293624267577\n",
            "Epoch [11/100], Loss: 47.4144; Val loss = 1347.861667175293\n",
            "Epoch [12/100], Loss: 79.1295; Val loss = 1265.4177485046387\n",
            "Epoch [13/100], Loss: 967.1780; Val loss = 1179.0775624084472\n",
            "Epoch [14/100], Loss: 47.3053; Val loss = 1101.9442671203612\n",
            "Epoch [15/100], Loss: 171.6196; Val loss = 1014.0583553771972\n",
            "Epoch [16/100], Loss: 35.4413; Val loss = 918.6614729309082\n",
            "Epoch [17/100], Loss: 8886172.0000; Val loss = 808.8276465759277\n",
            "Epoch [18/100], Loss: 36.7112; Val loss = 722.3304411621094\n",
            "Epoch [19/100], Loss: 50.1158; Val loss = 623.034933807373\n",
            "Epoch [20/100], Loss: 16241.1016; Val loss = 528.0594008483887\n",
            "Epoch [21/100], Loss: 34.0864; Val loss = 429.574241607666\n",
            "Epoch [22/100], Loss: 19.8383; Val loss = 323.93151542663577\n",
            "Epoch [23/100], Loss: 2454.9751; Val loss = 247.7958331680298\n",
            "Epoch [24/100], Loss: 11.9983; Val loss = 181.14075673675538\n",
            "Epoch [25/100], Loss: 7.9758; Val loss = 114.03758664894104\n",
            "Epoch [26/100], Loss: 5.3799; Val loss = 64.88946689605713\n",
            "Epoch [27/100], Loss: 7.7360; Val loss = 34.00957843494415\n",
            "Epoch [28/100], Loss: 2.7614; Val loss = 15.824771194458007\n",
            "Epoch [29/100], Loss: 3.8942; Val loss = 7.844872794151306\n",
            "Epoch [30/100], Loss: 3.8811; Val loss = 4.159661983489991\n",
            "Epoch [31/100], Loss: 1.4789; Val loss = 4.959047636032104\n",
            "Epoch [32/100], Loss: 1.0676; Val loss = 3.416778366088867\n",
            "Epoch [33/100], Loss: 2.7645; Val loss = 3.432827182292938\n",
            "Epoch [34/100], Loss: 1.3673; Val loss = 3.5495481357574463\n",
            "Epoch [35/100], Loss: 2.6756; Val loss = 10.89708752632141\n",
            "Epoch [36/100], Loss: 1.2353; Val loss = 2.299355351448059\n",
            "Epoch [37/100], Loss: 0.8782; Val loss = 2.9119097089767454\n",
            "Epoch [38/100], Loss: 1.4435; Val loss = 1.7803485600948334\n",
            "Epoch [39/100], Loss: 0.5595; Val loss = 2.553685200691223\n",
            "Epoch [40/100], Loss: 0.3872; Val loss = 4.264295401096344\n",
            "Epoch [41/100], Loss: 3.3923; Val loss = 1.2033738079071046\n",
            "Epoch [42/100], Loss: 0.4311; Val loss = 2.5261630492210387\n",
            "Epoch [43/100], Loss: 0.2506; Val loss = 1.9568836295604706\n",
            "Epoch [44/100], Loss: 0.1984; Val loss = 1.5781935279369355\n",
            "Epoch [45/100], Loss: 0.1545; Val loss = 1.1203619958758355\n",
            "Epoch [46/100], Loss: 5.1018; Val loss = 1.730530940592289\n",
            "Epoch [47/100], Loss: 0.1573; Val loss = 0.8207068872451783\n",
            "Epoch [48/100], Loss: 0.2336; Val loss = 1.4425212469697\n",
            "Epoch [49/100], Loss: 0.1609; Val loss = 1.017140255331993\n",
            "Epoch [50/100], Loss: 0.2706; Val loss = 0.44995565819740296\n",
            "Epoch [51/100], Loss: 0.2051; Val loss = 0.811771379172802\n",
            "Epoch [52/100], Loss: 0.0971; Val loss = 1.1328117592334748\n",
            "Epoch [53/100], Loss: 0.0567; Val loss = 0.70320959764719\n",
            "Epoch [54/100], Loss: 10.6996; Val loss = 0.47223605996370316\n",
            "Epoch [55/100], Loss: 0.0965; Val loss = 0.6712216326147318\n",
            "Epoch [56/100], Loss: 0.7219; Val loss = 0.5739298364818096\n",
            "Epoch [57/100], Loss: 0.0283; Val loss = 0.5405712282061577\n",
            "Epoch [58/100], Loss: 0.0729; Val loss = 0.6179809146523476\n",
            "Epoch [59/100], Loss: 0.0197; Val loss = 0.3999419674053788\n",
            "Epoch [60/100], Loss: 0.0465; Val loss = 0.36650706857442855\n",
            "Epoch [61/100], Loss: 0.0338; Val loss = 0.32624371081590653\n",
            "Epoch [62/100], Loss: 0.1030; Val loss = 0.3390183230042458\n",
            "Epoch [63/100], Loss: 0.0205; Val loss = 0.3533879788815975\n",
            "Epoch [64/100], Loss: 0.0281; Val loss = 0.5305619504451752\n",
            "Epoch [65/100], Loss: 0.0113; Val loss = 0.10380518409982324\n",
            "Epoch [66/100], Loss: 0.0255; Val loss = 0.20281284771114588\n",
            "Epoch [67/100], Loss: 0.0121; Val loss = 0.17641391704976558\n",
            "Epoch [68/100], Loss: 0.0256; Val loss = 0.12633771160244942\n",
            "Epoch [69/100], Loss: 0.0138; Val loss = 0.15936134713888167\n",
            "Epoch [70/100], Loss: 0.0221; Val loss = 0.3262659278064966\n",
            "Epoch [71/100], Loss: 0.2334; Val loss = 0.17463504474237562\n",
            "Epoch [72/100], Loss: 0.0055; Val loss = 0.5271858357191086\n",
            "Epoch [73/100], Loss: 0.0146; Val loss = 0.8193518401905894\n",
            "Epoch [74/100], Loss: 0.0156; Val loss = 0.07415897377580405\n",
            "Epoch [75/100], Loss: 0.2516; Val loss = 0.03462194129824638\n",
            "Epoch [76/100], Loss: 0.0097; Val loss = 0.08685776120424271\n",
            "Epoch [77/100], Loss: 0.0143; Val loss = 0.09522138837724924\n",
            "Epoch [78/100], Loss: 0.5876; Val loss = 0.10318715074285865\n",
            "Epoch [79/100], Loss: 0.9067; Val loss = 0.2490776687860489\n",
            "Epoch [80/100], Loss: 1.1053; Val loss = 0.1379468214549124\n",
            "Epoch [81/100], Loss: 0.0052; Val loss = 0.08212158247828484\n",
            "Epoch [82/100], Loss: 0.0096; Val loss = 0.26928893937915566\n",
            "Epoch [83/100], Loss: 0.0043; Val loss = 0.09387835398502647\n",
            "Epoch [84/100], Loss: 0.0148; Val loss = 0.06057223301380873\n",
            "Epoch [85/100], Loss: 0.0072; Val loss = 0.07150820761173964\n",
            "Epoch [86/100], Loss: 0.0074; Val loss = 0.10026945295277984\n",
            "Epoch [87/100], Loss: 0.1134; Val loss = 0.06261514794826507\n",
            "Epoch [88/100], Loss: 0.0212; Val loss = 0.12665690582059325\n",
            "Epoch [89/100], Loss: 0.0212; Val loss = 0.17682754217460753\n",
            "Epoch [90/100], Loss: 0.0130; Val loss = 0.1923131141141057\n",
            "Epoch [91/100], Loss: 0.0433; Val loss = 0.13541004916280508\n",
            "Epoch [92/100], Loss: 0.9018; Val loss = 0.15954373800661414\n",
            "Epoch [93/100], Loss: 0.0094; Val loss = 0.12626488249748946\n",
            "Epoch [94/100], Loss: 0.0065; Val loss = 0.21686505565419792\n",
            "Epoch [95/100], Loss: 0.0187; Val loss = 0.17564246909320355\n",
            "Epoch [96/100], Loss: 1.5065; Val loss = 0.2935135911228135\n",
            "Epoch [97/100], Loss: 0.0047; Val loss = 0.13699962823092937\n",
            "Epoch [98/100], Loss: 0.0047; Val loss = 0.16457993698492646\n",
            "Epoch [99/100], Loss: 0.0030; Val loss = 0.03229769869893789\n",
            "Epoch [100/100], Loss: 1.9480; Val loss = 0.9666583509072662\n"
          ]
        }
      ],
      "source": [
        "num_epochs =   100\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, targets) in enumerate(dataloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "    \n",
        "    val_loss = validate_model(model, val_loader, criterion, device)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}; Val loss = {val_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Uni8n80lIcuk"
      },
      "outputs": [],
      "source": [
        "import random as rand\n",
        "def XandYQuadValues(x1,x2,c):\n",
        "# Calculate 'a' from the y-intercept and x-intercepts\n",
        "    if x1 * x2 != 0:\n",
        "        a = c / (x1 * x2)\n",
        "    else:\n",
        "        a = 1  # Default to 1 if x1 or x2 is zero to avoid division by zero\n",
        "\n",
        "    # Define the range of x values to cover the extended plot\n",
        "    x_min = -50 # Extending beyond the smallest intercept\n",
        "    x_max = 50  # Extending beyond the largest intercept\n",
        "    x = np.linspace(x_min, x_max, 500)\n",
        "\n",
        "    # Calculate the corresponding y values based on the quadratic formula\n",
        "    y = a * (x - x1) * (x - x2)\n",
        "\n",
        "    return x,y,a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FmdtEo1kIc4C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(500, 1)\n",
            "          0         1         2\n",
            "0 -0.047473  1.278354 -7.046773\n"
          ]
        }
      ],
      "source": [
        "xydf = pd.DataFrame()\n",
        "abcdf = pd.DataFrame()\n",
        "x = pd.DataFrame([list([1,2,3])])\n",
        "\n",
        "for i in range(0,1):\n",
        "    x_int1 = rand.uniform(-25,25)\n",
        "    x_int2 = rand.uniform(-25,25)\n",
        "    factor = rand.uniform(-25,25)\n",
        "    x,y,a = XandYQuadValues(x_int1,x_int2,factor)\n",
        "    xdf = pd.DataFrame([list(x)])\n",
        "    ydf = pd.DataFrame([list(y)])\n",
        "    b = a*-(x_int1+x_int2)\n",
        "    c = a*x_int1*x_int2\n",
        "    if i == 0:\n",
        "        xydf = pd.concat([xdf,ydf])\n",
        "        abcdf = pd.DataFrame([[a, b, c]])\n",
        "    else:\n",
        "        xydf = pd.concat([xydf,ydf])\n",
        "        abcdf = pd.concat([abcdf, pd.DataFrame([list([a, b, c])])])\n",
        "\n",
        "\n",
        "xydfnp = xydf.iloc[1,:].to_numpy()\n",
        "xydfnp = np.expand_dims(xydfnp, axis=1)\n",
        "print(xydfnp.shape)\n",
        "test_tensor = torch.tensor(xydfnp, dtype=torch.float32)\n",
        "print(abcdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Output: [[-0.04483857  1.2781416  -7.0726333 ]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Matth\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():  # Turn off gradients since we're in inference mode\n",
        "    \n",
        "    test_tensor = test_tensor.view(1, -1)\n",
        "    test_tensor_scaled = scaler.transform(test_tensor)\n",
        "    outputs = model(torch.tensor(test_tensor_scaled, dtype=torch.float32))\n",
        "\n",
        "\n",
        "\n",
        "predicted_labels = outputs.detach().numpy()  # Convert to numpy \n",
        "print(\"Predicted Output:\", predicted_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
